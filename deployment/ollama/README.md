# Ollama

Ollama lets you run LLMs locally with just a few commands. It is available on macOS, Linux, and Windows. Learn more at the [Ollama website](https://ollama.com/).

This directory contains Ollama deployment guides for different MiniCPM versions. Use the links below to jump to the specific version.

## Versioned Deployment Guides

- MiniCPM-V 4.5: [English](./minicpm-v4_5_ollama.md) | [中文](./minicpm-v4_5_ollama_zh.md)
- MiniCPM-V 4.0: [English](./minicpm-v4_ollama.md) | [中文](./minicpm-v4_ollama_zh.md)
